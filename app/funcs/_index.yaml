version: "1.0"
namespace: app.funcs.openai

meta:
  depends_on: [ ns:wippy.llm ]

entries:
  - name: llm_query
    kind: function.lua
    meta:
      comment: "LLM query function for chat sessions using Wippy.LLM"
    source: file://llm_query.lua
    method: llm_query
    modules: [ "json" ]
    imports:
      llm: wippy.llm:llm
      prompt: wippy.llm:prompt
